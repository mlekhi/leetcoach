{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../resource.mjs\";\nimport * as Core from \"../../core.mjs\";\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(body, options) {\n    return this._client.post('/openai/v1/audio/transcriptions', Core.multipartFormRequestOptions({\n      body,\n      ...options\n    }));\n  }\n}\n(function (Transcriptions) {})(Transcriptions || (Transcriptions = {}));","map":{"version":3,"names":["APIResource","Core","Transcriptions","create","body","options","_client","post","multipartFormRequestOptions"],"sources":["/Users/madhavmalik/VSC Projects/leetcoach/client/node_modules/groq-sdk/src/resources/audio/transcriptions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as TranscriptionsAPI from './transcriptions';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription> {\n    return this._client.post(\n      '/openai/v1/audio/transcriptions',\n      Core.multipartFormRequestOptions({ body, ...options }),\n    );\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n}\n\nexport interface TranscriptionCreateParams {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-large-v3` is currently available.\n   */\n  model: (string & {}) | 'whisper-large-v3';\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will\n   * improve accuracy and latency.\n   */\n  language?:\n    | (string & {})\n    | 'en'\n    | 'zh'\n    | 'de'\n    | 'es'\n    | 'ru'\n    | 'ko'\n    | 'fr'\n    | 'ja'\n    | 'pt'\n    | 'tr'\n    | 'pl'\n    | 'ca'\n    | 'nl'\n    | 'ar'\n    | 'sv'\n    | 'it'\n    | 'id'\n    | 'hi'\n    | 'fi'\n    | 'vi'\n    | 'he'\n    | 'uk'\n    | 'el'\n    | 'ms'\n    | 'cs'\n    | 'ro'\n    | 'da'\n    | 'hu'\n    | 'ta'\n    | 'th'\n    | 'ur'\n    | 'hr'\n    | 'bg'\n    | 'lt'\n    | 'la'\n    | 'mi'\n    | 'ml'\n    | 'cy'\n    | 'sk'\n    | 'te'\n    | 'fa'\n    | 'lv'\n    | 'bn'\n    | 'sr'\n    | 'az'\n    | 'sl'\n    | 'kn'\n    | 'et'\n    | 'mk'\n    | 'br'\n    | 'eu'\n    | 'is'\n    | 'hy'\n    | 'ne'\n    | 'mn'\n    | 'bs'\n    | 'kk'\n    | 'sq'\n    | 'sw'\n    | 'gl'\n    | 'mr'\n    | 'pa'\n    | 'si'\n    | 'km'\n    | 'sn'\n    | 'yo'\n    | 'so'\n    | 'af'\n    | 'oc'\n    | 'ka'\n    | 'be'\n    | 'tg'\n    | 'sd'\n    | 'gu'\n    | 'am'\n    | 'yi'\n    | 'lo'\n    | 'uz'\n    | 'fo'\n    | 'ht'\n    | 'ps'\n    | 'tk'\n    | 'nn'\n    | 'mt'\n    | 'sa'\n    | 'lb'\n    | 'my'\n    | 'bo'\n    | 'tl'\n    | 'mg'\n    | 'as'\n    | 'tt'\n    | 'haw'\n    | 'ln'\n    | 'ha'\n    | 'ba'\n    | 'jv'\n    | 'su'\n    | 'yue';\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the\n   * audio language.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the transcript output, in one of these options: `json`, `text`, or\n   * `verbose_json`.\n   */\n  response_format?: 'json' | 'text' | 'verbose_json';\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport namespace Transcriptions {\n  export import Transcription = TranscriptionsAPI.Transcription;\n  export import TranscriptionCreateParams = TranscriptionsAPI.TranscriptionCreateParams;\n}\n"],"mappings":"AAAA;SAESA,WAAW,QAAE;OACf,KAAKC,IAAI;AAGhB,OAAM,MAAOC,cAAe,SAAQF,WAAW;EAC7C;;;EAGAG,MAAMA,CAACC,IAA+B,EAAEC,OAA6B;IACnE,OAAO,IAAI,CAACC,OAAO,CAACC,IAAI,CACtB,iCAAiC,EACjCN,IAAI,CAACO,2BAA2B,CAAC;MAAEJ,IAAI;MAAE,GAAGC;IAAO,CAAE,CAAC,CACvD;EACH;;AAqKF,WAAiBH,cAAc,GAG/B,CAAC,EAHgBA,cAAc,KAAdA,cAAc","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}